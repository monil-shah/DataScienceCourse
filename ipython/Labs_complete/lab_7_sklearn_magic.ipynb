{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this lab we'll demonstrate several common techniques and helpful tools used in a model building process:\n",
    "\n",
    "- Use Sklearn to generate polynomial features and rescale them\n",
    "- Create folds for cross-validation\n",
    "- Perform a grid search to optimize hyper-parameters using cross-validation\n",
    "- Create pipelines to perform grids search in less code\n",
    "- Improve upon a baseline model incrementally by adding in more complexity\n",
    "\n",
    "This lab will require using several Sklearn classes. It would be helpful to refer to appropriate documentation:\n",
    "- http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "- http://scikit-learn.org/stable/modules/pipeline.html#pipeline\n",
    "\n",
    "Also, here is a helpful tutorial that explains how to use much of the above:\n",
    "- https://civisanalytics.com/blog/data-science/2016/01/06/workflows-python-using-pipeline-gridsearchcv-for-compact-code/\n",
    "\n",
    "Like always, let's first load in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['revenue', 'outcalls', 'incalls', 'months', 'eqpdays', 'webcap',\n",
       "       'marryyes', 'travel', 'pcown', 'creditcd', 'retcalls', 'churndep'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "cwd = os.getcwd()\n",
    "datadir = '/'.join(cwd.split('/')[0:-1]) + '/data/'\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(datadir + 'Cell2Cell_data.csv', header=0, sep=',')\n",
    "\n",
    "#Randomly sort the data:\n",
    "data = data.sample(frac = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to prep the data. From prior analysis (Churn Case Study) we learned that we can drop a few variables, as they are either highly redundant or don't carry a strong relationship with the outcome.\n",
    "\n",
    "After dropping, we're going to use the SkLearn KFold class to set up cross validation fold indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prior analysis (from Churn Case study) has shown that we can drop a few redundant variables\n",
    "#We want to drop a few to speed up later calculations\n",
    "dropvar_list = ['incalls', 'creditcd', 'marryyes', 'travel', 'pcown']\n",
    "data_subset = data.drop(dropvar_list, 1)\n",
    "\n",
    "#Set up X and Y\n",
    "X = data_subset.drop('churndep', 1)\n",
    "Y = data_subset['churndep']\n",
    "\n",
    "#Use Kfold to create 4 folds\n",
    "kfolds = KFold(data_subset.shape[0], n_folds = 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's use cross-validation to build a baseline model. We're going to use LR with no feature pre-processing. We're going to look at both L1 and L2 regularization with different weights. We can do this very succinctly with SkLearns GridSearchCV package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.682495178553\n"
     ]
    }
   ],
   "source": [
    "#1st, set up a paramater grid\n",
    "param_grid_lr = {'C':[10**i for i in range(-3, 3)], 'penalty':['l1', 'l2']}\n",
    "\n",
    "#2nd, call the GridSearchCV class, use LogisticRegression and 'log_loss' for scoring\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), param_grid_lr, cv = kfolds, scoring = 'log_loss') \n",
    "lr_grid_search.fit(X, Y)\n",
    "\n",
    "#3rd, get the score of the best model and print it\n",
    "best_1 = lr_grid_search.best_score_\n",
    "print(best_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next let's look at the best-estimator chosen to see what the parameters were\n",
    "lr_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can beat this by standardizing the features. We'll approach this using the GridSearchCV class but also build a pipeline. Later we'll extend the pipeline to allow for feature engineering as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.682490465504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Create a set of steps. All but the last step is a transformer (something that processes data). \n",
    "#Build a list of steps, where the first is StandardScaler and the second is LogisticRegression\n",
    "#The last step should be an estimator.\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression())]\n",
    "\n",
    "#Now set up the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#Now set up the parameter grid, paying close to the correct convention here\n",
    "parameters_scaler = dict(lr__C = [10**i for i in range(-3, 3)],\n",
    "                  lr__penalty = ['l1', 'l2'])\n",
    "\n",
    "#Now run another grid search\n",
    "lr_grid_search_scaler = GridSearchCV(pipeline, param_grid = parameters_scaler, cv = kfolds, scoring = 'log_loss')\n",
    "lr_grid_search_scaler.fit(X, Y)\n",
    "\n",
    "\n",
    "#Again, print the score of the best model\n",
    "best_2 = lr_grid_search_scaler.best_score_\n",
    "print(best_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see the model after scaling. Did the optimal parameters change?\n",
    "lr_grid_search_scaler.best_estimator_.steps[-1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've built a pipeline estimator that performs feature scaling and then logistic regression, let's add to it a feature engineering step. We'll then again use GridSearchCV to find an optimal parameter configuration and see if we can beat our best score above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.68035039448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Create a set of steps. All but the last step is a transformer (something that processes data). \n",
    "# Step 1 - PolynomialFeatures\n",
    "# Step 2 - StandardScaler\n",
    "# Step 3 - LogisticRegression\n",
    "\n",
    "steps_poly = [('polyfeat', PolynomialFeatures()),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression())]\n",
    "\n",
    "#Now set up the pipeline\n",
    "pipeline_poly = Pipeline(steps_poly)\n",
    "\n",
    "#Now set up a new parameter grid, use the same paramaters used above for logistic regression, but add polynomial features up to degree 3. \n",
    "parameters_poly = dict(polyfeat__degree = [1, 2],\n",
    "                       polyfeat__interaction_only = [True, False],\n",
    "                       lr__C = [10**i for i in range(-3, 3)],\n",
    "                       lr__penalty = ['l1', 'l2'])\n",
    "\n",
    "#Now run another grid search\n",
    "lr_grid_search_poly = GridSearchCV(pipeline_poly, param_grid = parameters_poly, cv = kfolds, scoring = 'log_loss')\n",
    "\n",
    "lr_grid_search_poly.fit(X, Y)\n",
    "best_3 = lr_grid_search_poly.best_score_\n",
    "print(best_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('polyfeat',\n",
       "  PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)),\n",
       " ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('lr',\n",
       "  LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at the best estimator, stepwise\n",
    "lr_grid_search_poly.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a bar chart to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10c294da0>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAF0CAYAAAAggv9WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny6ctAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c2ac2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "results = -1 * np.array([best_1, best_2, best_3])\n",
    "labs = ['LR', 'Scaler-LR', 'Poly-Scaler-LR']\n",
    "\n",
    "fig = plt.figure(facecolor = 'w', figsize = (12, 6))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "width = 0.5\n",
    "ind = np.arange(3)\n",
    "rec = ax.bar(ind + width, results, width, color='r')\n",
    "\n",
    "ax.set_xticks(ind + width)\n",
    "ax.set_xticklabels(labs, size = 14)\n",
    "ax.set_ylim([0.6, 0.7])\n",
    "\n",
    "plt.plot(np.arange(4), min(results) * np.ones(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
